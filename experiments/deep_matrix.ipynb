{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284781b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b47918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b1dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"\"\n",
    "\n",
    "\n",
    "def read_data_df() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Reads in data and splits it into training and validation sets with a 75/25 split.\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"train_ratings.csv\"))\n",
    "\n",
    "    # Split sid_pid into sid and pid columns\n",
    "    df[[\"sid\", \"pid\"]] = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    df = df.drop(\"sid_pid\", axis=1)\n",
    "    df[\"sid\"] = df[\"sid\"].astype(int)\n",
    "    df[\"pid\"] = df[\"pid\"].astype(int)\n",
    "    \n",
    "    # Split into train and validation dataset\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.01)\n",
    "    return train_df, valid_df\n",
    "\n",
    "\n",
    "def read_data_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Returns matrix view of the training data, where columns are scientists (sid) and\n",
    "    rows are papers (pid).\"\"\"\n",
    "\n",
    "    return df.pivot(index=\"sid\", columns=\"pid\", values=\"rating\").values\n",
    "\n",
    "\n",
    "def evaluate(valid_df: pd.DataFrame, pred_fn: Callable[[np.ndarray, np.ndarray], np.ndarray]) -> float:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        valid_df: Validation data, returned from read_data_df for example.\n",
    "        pred_fn: Function that takes in arrays of sid and pid and outputs their rating predictions.\n",
    "\n",
    "    Outputs: Validation RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = pred_fn(valid_df[\"sid\"].values, valid_df[\"pid\"].values)\n",
    "    return root_mean_squared_error(valid_df[\"rating\"].values, preds)\n",
    "\n",
    "\n",
    "def make_submission(pred_fn: Callable[[np.ndarray, np.ndarray], np.ndarray], filename: os.PathLike):\n",
    "    \"\"\"Makes a submission CSV file that can be submitted to kaggle.\n",
    "\n",
    "    Inputs:\n",
    "        pred_fn: Function that takes in arrays of sid and pid and outputs a score.\n",
    "        filename: File to save the submission to.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "    # Get sids and pids\n",
    "    sid_pid = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    sids = sid_pid[0]\n",
    "    pids = sid_pid[1]\n",
    "    sids = sids.astype(int).values\n",
    "    pids = pids.astype(int).values\n",
    "    \n",
    "    df[\"rating\"] = pred_fn(sids, pids)\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e61f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = read_data_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a237a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f822ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df: pd.DataFrame) -> torch.utils.data.Dataset:\n",
    "    \"\"\"Conversion from pandas data frame to torch dataset.\"\"\"\n",
    "    \n",
    "    sids = torch.from_numpy(df[\"sid\"].to_numpy())\n",
    "    pids = torch.from_numpy(df[\"pid\"].to_numpy())\n",
    "    ratings = torch.from_numpy(df[\"rating\"].to_numpy()).float()\n",
    "    return torch.utils.data.TensorDataset(sids, pids, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0433f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Returns matrix view of the training data, where columns are scientists (sid) and\n",
    "    rows are papers (pid).\"\"\"\n",
    "\n",
    "    return df.pivot(index=\"sid\", columns=\"pid\", values=\"rating\").values\n",
    "\n",
    "def impute_values(mat: np.ndarray) -> np.ndarray:\n",
    "    return np.nan_to_num(mat, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dee0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = read_data_matrix(train_df)\n",
    "Y = impute_values(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea887de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_tbr() -> pd.DataFrame:\n",
    "    \"\"\"Reads in wishlist data\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"train_tbr.csv\"))\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3559cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wishlist_df = read_data_tbr()\n",
    "wishlist_df[\"rating\"] = 1\n",
    "\n",
    "missing_sids = []\n",
    "for i in range(10000):\n",
    "    if wishlist_df[wishlist_df[\"sid\"] == i].shape[0] == 0:\n",
    "        missing_sids.append(i)\n",
    "        \n",
    "for i in range(len(missing_sids)):\n",
    "    wishlist_df = pd.concat([wishlist_df, pd.DataFrame({\"sid\": [missing_sids[i]], \"pid\": [0], \"rating\": [0]})], ignore_index=True)\n",
    "\n",
    "wishlist = read_data_matrix(wishlist_df)\n",
    "wishlist = impute_values(wishlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8e20981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepMatrixFactorizationModel(nn.Module):\n",
    "    def __init__(self, num_scientists: int, num_papers: int, dim: int, hidden_dim: int, Y: np.ndarray, rating: np.ndarray):\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_buffer(\"Y\", torch.from_numpy(Y).float())\n",
    "        self.register_buffer(\"rating\", torch.from_numpy(rating).float())\n",
    "\n",
    "        \n",
    "        self.scientist_nn = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_papers, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.paper_nn = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_scientists, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.srating_nn = nn.Sequential(\n",
    "            nn.Linear(num_papers, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.prating_nn = nn.Sequential(\n",
    "            nn.Linear(num_scientists, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.final_nn = nn.Sequential(\n",
    "            nn.Linear(4*dim, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, sid: torch.Tensor, pid: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            sid: [B,], int\n",
    "            pid: [B,], int\n",
    "        \n",
    "        Outputs: [B,], float\n",
    "        \"\"\"\n",
    "        scientist_row = self.Y[sid, :]\n",
    "        paper_row = self.Y[:, pid].T\n",
    "\n",
    "        srating_row = self.rating[sid, :]\n",
    "        prating_row = self.rating[:, pid].T\n",
    "\n",
    "        \n",
    "\n",
    "        p = self.scientist_nn(scientist_row)\n",
    "        q = self.paper_nn(paper_row)\n",
    "\n",
    "        srating = self.srating_nn(srating_row)\n",
    "        prating = self.prating_nn(prating_row)\n",
    "        \n",
    "        #r = p * srating\n",
    "        #sr = q * prating\n",
    "\n",
    "\n",
    "        # Per-pair dot product\n",
    "        return self.final_nn(torch.cat([p,q,srating,prating], dim=1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f0e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (10k scientists, 1k papers, 32-dimensional embeddings) and optimizer\n",
    "model = DeepMatrixFactorizationModel(10_000, 1_000, 40, 40, Y, wishlist).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5*1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a838e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(train_df)\n",
    "valid_dataset = get_dataset(valid_df)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ec715ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/30] Train loss=0.928, Valid RMSE=0.919\n",
      "[Epoch 2/30] Train loss=0.822, Valid RMSE=0.890\n",
      "[Epoch 3/30] Train loss=0.801, Valid RMSE=0.897\n",
      "[Epoch 4/30] Train loss=0.790, Valid RMSE=0.894\n",
      "[Epoch 5/30] Train loss=0.782, Valid RMSE=0.884\n",
      "[Epoch 6/30] Train loss=0.776, Valid RMSE=0.878\n",
      "[Epoch 7/30] Train loss=0.771, Valid RMSE=0.898\n",
      "[Epoch 8/30] Train loss=0.768, Valid RMSE=0.876\n",
      "[Epoch 9/30] Train loss=0.764, Valid RMSE=0.874\n",
      "[Epoch 10/30] Train loss=0.761, Valid RMSE=0.873\n",
      "[Epoch 11/30] Train loss=0.758, Valid RMSE=0.870\n",
      "[Epoch 12/30] Train loss=0.755, Valid RMSE=0.877\n",
      "[Epoch 13/30] Train loss=0.752, Valid RMSE=0.869\n",
      "[Epoch 14/30] Train loss=0.750, Valid RMSE=0.869\n",
      "[Epoch 15/30] Train loss=0.748, Valid RMSE=0.869\n",
      "[Epoch 16/30] Train loss=0.745, Valid RMSE=0.867\n",
      "[Epoch 17/30] Train loss=0.744, Valid RMSE=0.866\n",
      "[Epoch 18/30] Train loss=0.742, Valid RMSE=0.868\n",
      "[Epoch 19/30] Train loss=0.740, Valid RMSE=0.863\n",
      "[Epoch 20/30] Train loss=0.739, Valid RMSE=0.868\n",
      "[Epoch 21/30] Train loss=0.737, Valid RMSE=0.865\n",
      "[Epoch 22/30] Train loss=0.736, Valid RMSE=0.862\n",
      "[Epoch 23/30] Train loss=0.734, Valid RMSE=0.862\n",
      "[Epoch 24/30] Train loss=0.732, Valid RMSE=0.862\n",
      "[Epoch 25/30] Train loss=0.731, Valid RMSE=0.863\n",
      "[Epoch 26/30] Train loss=0.730, Valid RMSE=0.862\n",
      "[Epoch 27/30] Train loss=0.728, Valid RMSE=0.862\n",
      "[Epoch 28/30] Train loss=0.727, Valid RMSE=0.860\n",
      "[Epoch 29/30] Train loss=0.725, Valid RMSE=0.860\n",
      "[Epoch 30/30] Train loss=0.725, Valid RMSE=0.861\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6ea44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/30] Train loss=0.723, Valid RMSE=0.860\n",
      "[Epoch 2/30] Train loss=0.722, Valid RMSE=0.860\n",
      "[Epoch 3/30] Train loss=0.721, Valid RMSE=0.859\n",
      "[Epoch 4/30] Train loss=0.720, Valid RMSE=0.861\n",
      "[Epoch 5/30] Train loss=0.719, Valid RMSE=0.861\n",
      "[Epoch 6/30] Train loss=0.718, Valid RMSE=0.860\n",
      "[Epoch 7/30] Train loss=0.717, Valid RMSE=0.859\n",
      "[Epoch 8/30] Train loss=0.716, Valid RMSE=0.862\n",
      "[Epoch 9/30] Train loss=0.715, Valid RMSE=0.860\n",
      "[Epoch 10/30] Train loss=0.714, Valid RMSE=0.857\n",
      "[Epoch 11/30] Train loss=0.714, Valid RMSE=0.857\n",
      "[Epoch 12/30] Train loss=0.713, Valid RMSE=0.859\n",
      "[Epoch 13/30] Train loss=0.711, Valid RMSE=0.858\n",
      "[Epoch 14/30] Train loss=0.711, Valid RMSE=0.857\n",
      "[Epoch 15/30] Train loss=0.710, Valid RMSE=0.855\n",
      "[Epoch 16/30] Train loss=0.709, Valid RMSE=0.855\n",
      "[Epoch 17/30] Train loss=0.708, Valid RMSE=0.857\n",
      "[Epoch 18/30] Train loss=0.708, Valid RMSE=0.857\n",
      "[Epoch 19/30] Train loss=0.707, Valid RMSE=0.855\n",
      "[Epoch 20/30] Train loss=0.706, Valid RMSE=0.856\n",
      "[Epoch 21/30] Train loss=0.706, Valid RMSE=0.854\n",
      "[Epoch 22/30] Train loss=0.704, Valid RMSE=0.856\n",
      "[Epoch 23/30] Train loss=0.704, Valid RMSE=0.858\n",
      "[Epoch 24/30] Train loss=0.704, Valid RMSE=0.859\n",
      "[Epoch 25/30] Train loss=0.703, Valid RMSE=0.857\n",
      "[Epoch 26/30] Train loss=0.702, Valid RMSE=0.856\n",
      "[Epoch 27/30] Train loss=0.702, Valid RMSE=0.855\n",
      "[Epoch 28/30] Train loss=0.702, Valid RMSE=0.855\n",
      "[Epoch 29/30] Train loss=0.701, Valid RMSE=0.859\n",
      "[Epoch 30/30] Train loss=0.700, Valid RMSE=0.857\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32a6e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] Train loss=0.700, Valid RMSE=0.855\n",
      "[Epoch 2/5] Train loss=0.699, Valid RMSE=0.857\n",
      "[Epoch 3/5] Train loss=0.698, Valid RMSE=0.859\n",
      "[Epoch 4/5] Train loss=0.698, Valid RMSE=0.857\n",
      "[Epoch 5/5] Train loss=0.697, Valid RMSE=0.857\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda8f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] Train loss=0.697, Valid RMSE=0.860\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a95f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] Train loss=0.696, Valid RMSE=0.854\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cecac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] Train loss=0.696, Valid RMSE=0.856\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "340ec702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] Train loss=0.695, Valid RMSE=0.855\n",
      "[Epoch 2/10] Train loss=0.695, Valid RMSE=0.862\n",
      "[Epoch 3/10] Train loss=0.694, Valid RMSE=0.856\n",
      "[Epoch 4/10] Train loss=0.694, Valid RMSE=0.856\n",
      "[Epoch 5/10] Train loss=0.693, Valid RMSE=0.856\n",
      "[Epoch 6/10] Train loss=0.693, Valid RMSE=0.854\n",
      "[Epoch 7/10] Train loss=0.692, Valid RMSE=0.854\n",
      "[Epoch 8/10] Train loss=0.692, Valid RMSE=0.859\n",
      "[Epoch 9/10] Train loss=0.692, Valid RMSE=0.858\n",
      "[Epoch 10/10] Train loss=0.691, Valid RMSE=0.855\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f047d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] Train loss=0.691, Valid RMSE=0.855\n",
      "[Epoch 2/5] Train loss=0.690, Valid RMSE=0.853\n",
      "[Epoch 3/5] Train loss=0.690, Valid RMSE=0.855\n",
      "[Epoch 4/5] Train loss=0.689, Valid RMSE=0.854\n",
      "[Epoch 5/5] Train loss=0.689, Valid RMSE=0.855\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e571afd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 20\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Keep track of running loss\u001b[39;00m\n\u001b[1;32m     23\u001b[0m total_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sid)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/CIL/lib/python3.10/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/CIL/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/CIL/lib/python3.10/site-packages/torch/optim/adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    237\u001b[0m         group,\n\u001b[1;32m    238\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         state_steps,\n\u001b[1;32m    244\u001b[0m     )\n\u001b[0;32m--> 246\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/CIL/lib/python3.10/site-packages/torch/optim/optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/CIL/lib/python3.10/site-packages/torch/optim/adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 933\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/CIL/lib/python3.10/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    436\u001b[0m     device_beta1 \u001b[38;5;241m=\u001b[39m beta1\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m differentiable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta2, Tensor):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 17\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90cbb6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.855\n"
     ]
    }
   ],
   "source": [
    "def batched_pred_fn(sids, pids, batch_size=1024):\n",
    "    results = []\n",
    "    num_samples = len(sids)\n",
    "    \n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_sids = sids[i:i+batch_size]\n",
    "        batch_pids = pids[i:i+batch_size]\n",
    "        \n",
    "        batch_sids_tensor = torch.from_numpy(batch_sids).to(device)\n",
    "        batch_pids_tensor = torch.from_numpy(batch_pids).to(device)\n",
    "        \n",
    "        batch_preds = model(batch_sids_tensor, batch_pids_tensor).clamp(1, 5).cpu().numpy()\n",
    "        results.append(batch_preds)\n",
    "        \n",
    "        del batch_sids_tensor, batch_pids_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return np.concatenate(results)\n",
    "\n",
    "# Evaluate on validation data\n",
    "with torch.no_grad():\n",
    "    # First clear any unused memory\n",
    "    torch.cuda.empty_cache()\n",
    "    val_score = evaluate(valid_df, batched_pred_fn)\n",
    "\n",
    "print(f\"Validation RMSE: {val_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a765847",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    make_submission(batched_pred_fn, \"deep_matrix_submission_wish_dropout_83epochs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
